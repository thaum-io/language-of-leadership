{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Meaning\n",
    "Do the meanings of words used in the political discourse change over time, can we quantify this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from collections import Counter, defaultdict\n",
    "from nltk.stem import PorterStemmer\n",
    "from fuzzysearch import find_near_matches\n",
    "import swifter \n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import datetime\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "stop_words = stop_words.union(set(['ladies', 'gentlemen']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add repo\n",
    "git_dir = os.path.abspath('../')\n",
    "sys.path.append(os.path.join(git_dir, 'lib', 'utils') )\n",
    "\n",
    "data_output_path = os.path.join(git_dir, 'data', 'hansard-parsed')\n",
    "\n",
    "# Pickle path\n",
    "df_pickle_path = os.path.join(data_output_path, 'hansard-senate-emotions-ekman.pkl')\n",
    "\n",
    "# shared-scratch/language-of-leadership/data/hansard-parsed/hansard-senate-emotions-ekman.pkl\n",
    "# Read in, make string lists into strings\n",
    "df = pd.read_pickle(df_pickle_path)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All other types dont have enough structure.\n",
    "df['year'] = pd.DatetimeIndex(df['date']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline language data\n",
    "# flat_corpus = ' '.join(df.sentences.sum())\n",
    "# token_corpus = word_tokenize(flat_corpus)\n",
    "# token_corpus_filtered = [w for w in token_corpus if not w in stop_words]\n",
    "# corpus_freqs = Counter(token_corpus_filtered)\n",
    "# most_common = corpus_freqs.most_common(300)\n",
    "# corpus_norm = len(token_corpus_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woi = {\n",
    "    'ind': ['aboriginal', 'first nations', 'aborigine', 'indigenous', 'torres strait island'],\n",
    "    'econ': ['economy', 'economic'],\n",
    "    'aus': ['australia', 'australian', 'aussie', 'australians'],\n",
    "    'gov': ['government'],\n",
    "    'ref': ['immigrant', 'asylum seeker', 'boat people', 'illegal arrivals', 'boat arrivals', 'boat'],\n",
    "    'env': ['fire', 'bushfire', 'climate change', 'climate action', 'extinction', 'global warming', 'greenhouse', 'emissions', 'environment', 'coral reef', 'reef', 'climate', 'degradation', 'sustainability']\n",
    "}\n",
    "filters = {\n",
    "    'ind': [\n",
    "           'aboriginal', \n",
    "           'first nations', \n",
    "           'aborigine', \n",
    "           'indigenous', \n",
    "           'torres', \n",
    "           'strait', \n",
    "           'island',\n",
    "           'australia', \n",
    "           'australian', \n",
    "           'aussie',\n",
    "           'australians',\n",
    "           'government',\n",
    "           'nation',\n",
    "           'year',\n",
    "           'country'\n",
    "          ],\n",
    "    'econ': [\n",
    "        'economy', \n",
    "        'economic',\n",
    "        'australia', \n",
    "        'australian', \n",
    "        'aussie',\n",
    "        'australians',\n",
    "        'government',\n",
    "        'nation',\n",
    "        'year',\n",
    "        'country'\n",
    "    ],\n",
    "    'gov': [\n",
    "        'australia', \n",
    "        'australian', \n",
    "        'aussie',\n",
    "        'australians',\n",
    "        'government',\n",
    "        'nation',\n",
    "        'year',\n",
    "        'country' \n",
    "    ],\n",
    "    'gen': [\n",
    "        'australia', \n",
    "        'australian', \n",
    "        'aussie',\n",
    "        'australians',\n",
    "        'government',\n",
    "        'nation',\n",
    "        'year',\n",
    "        'country' \n",
    "    ],\n",
    "    'ref': [\n",
    "        'aboriginal', \n",
    "        'first nations', \n",
    "        'aborigine', \n",
    "        'indigenous', \n",
    "        'torres', \n",
    "        'strait', \n",
    "        'island',\n",
    "        'australia', \n",
    "        'australian', \n",
    "        'aussie',\n",
    "        'australians',\n",
    "        'government',\n",
    "        'nation',\n",
    "        'year',\n",
    "        'country' \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_colocation_neighbours(idxs_in, size, dist = 1):\n",
    "    idxs = idxs_in.copy()\n",
    "    for idx in idxs:\n",
    "        for d in range(dist):\n",
    "            if not idx - d < 0:\n",
    "                idxs_in.append(idx-d) \n",
    "            if not idx + d > size:\n",
    "                idxs_in.append(idx+d)\n",
    "\n",
    "def fuzzy_colocation(sequences, search_key, stemmer):\n",
    "    ret = []\n",
    "    for index, sequence in enumerate(sequences):\n",
    "        if any([len(find_near_matches(subsequence, sequence, max_l_dist=2)) > 0 \n",
    "             for subsequence in search_key]):\n",
    "            ret.append(index)\n",
    "    find_colocation_neighbours(ret, len(sequences))\n",
    "    acc = ' '.join([sequences[indx] for indx in ret])\n",
    "    return Counter([stemmer.stem(w) \n",
    "            for w in word_tokenize(acc) \n",
    "            if not w in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cooccurence(\n",
    "    search_key,\n",
    "    key,\n",
    "    filters\n",
    "):\n",
    "    search_key = woi[key]\n",
    "    df[f'{key}'] = df['sentences']\\\n",
    "        .progress_map(lambda x: fuzzy_colocation(x, search_key, PorterStemmer()))\n",
    "\n",
    "    cooccur_number = df.groupby('year')[key].sum()\n",
    "    total_freqs = cooccur_number.sum()\n",
    "\n",
    "    timeseries = defaultdict(list)\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_filter = [stemmer.stem(x) for x in filters]\n",
    "\n",
    "    timeseries = defaultdict(list)\n",
    "    for x in total_freqs:\n",
    "        if x not in stemmed_filter:\n",
    "            for counter in cooccur_number.to_list():\n",
    "                timeseries[x].append(counter.get(x, 0))\n",
    "\n",
    "    totals = {}\n",
    "    for w in timeseries:\n",
    "        totals[w] = sum(timeseries[w])\n",
    "\n",
    "    most_common = list(dict(Counter(totals).most_common(20)).keys())\n",
    "\n",
    "    return cooccur_number, most_common, timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coccurence(\n",
    "    key,\n",
    "    cooccur_number,\n",
    "    most_common,\n",
    "    timeseries,\n",
    "    group,\n",
    "    context\n",
    "):\n",
    "    for x in most_common[group[0]:group[1]]:\n",
    "        plt.plot(cooccur_number.index, gaussian_filter1d(timeseries[x], sigma=2))\n",
    "        plt.legend(most_common[group[0]:group[1]])\n",
    "    plt.title(f'Language Addressing {context} Issues')\n",
    "    plt.savefig(f'{fig_dir}/{group[0]}-{group[1]}-{key}-hansard.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_plot(\n",
    "    search_key,\n",
    "    key,\n",
    "    filters,\n",
    "    context\n",
    "):\n",
    "    cooccur_number, most_common, timeseries = get_cooccurence(search_key,key,filters)\n",
    "    plot_coccurence(\n",
    "        key,\n",
    "        cooccur_number,\n",
    "        most_common,\n",
    "        timeseries,\n",
    "        (0,5),\n",
    "        context\n",
    "    )\n",
    "    plot_coccurence(\n",
    "        key,\n",
    "        cooccur_number,\n",
    "        most_common,\n",
    "        timeseries,\n",
    "        (5,10),\n",
    "        context\n",
    "    )\n",
    "    plot_coccurence(\n",
    "        key,\n",
    "        cooccur_number,\n",
    "        most_common,\n",
    "        timeseries,\n",
    "        (10,15),\n",
    "        context\n",
    "    )\n",
    "    plot_coccurence(\n",
    "        key,\n",
    "        cooccur_number,\n",
    "        most_common,\n",
    "        timeseries,\n",
    "        (15,20),\n",
    "        context\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'aus'\n",
    "generate_and_plot(woi[key], key, filters['ind'], 'First Nations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'econ'\n",
    "generate_and_plot(woi[key], key, filters['econ'], 'Economics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'ref'\n",
    "generate_and_plot(woi[key], key, filters['ref'], 'Refugee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'env'\n",
    "generate_and_plot(woi[key], key, filters['env'], 'Environment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
