{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Word Meaning\n",
    "Do the meanings of words used in the political discourse change over time, can we quantify this? But this time we will be using a BERT GoEmotions model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "\n",
    "# from transformers import BertTokenizer\n",
    "# from model import BertForMultiLabelClassification\n",
    "# from multilabel_pipeline import MultiLabelPipeline\n",
    "from fuzzysearch import find_near_matches\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import dateparser\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "git_dir = os.path.abspath('../')\n",
    "\n",
    "# Define data path\n",
    "data_path = os.path.join(git_dir, 'data', 'pm-transcripts')\\\n",
    "\n",
    "# Define data output path\n",
    "data_output_path = os.path.join(git_dir, 'data', 'hansard-parsed')\n",
    "\n",
    "# Pickle path\n",
    "df_pickle_path = os.path.join(data_output_path, 'hansard-senate-emotions-ekman.pkl')\n",
    "\n",
    "# shared-scratch/language-of-leadership/data/hansard-parsed/hansard-senate-emotions-ekman.pkl\n",
    "#Read in, make string lists into strings\n",
    "df = pd.read_pickle(df_pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns and set a datetime index.\n",
    "def clean_df(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date').set_index('date')\n",
    "    return df \n",
    "\n",
    "df = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise_emotion(emotion, em_map):\n",
    "    arr = np.zeros(len(em_map))\n",
    "    for idx, em in enumerate(emotion['labels']):\n",
    "        arr[em_map[em]] = emotion['scores'][idx]\n",
    "    return arr\n",
    "\n",
    "def fuzzy_colocation(sequences, search_key):\n",
    "    ret = []\n",
    "    for index, sequence in enumerate(sequences):\n",
    "        if any([len(find_near_matches(subsequence, sequence, max_l_dist=2)) > 0 \n",
    "             for subsequence in search_key]):\n",
    "            ret.append(index)\n",
    "        # Return neighbour indicies?\n",
    "    return ret\n",
    "\n",
    "def generate_keyword_in_context_sentiment(\n",
    "    df_pass, # Copied after pass, new df is returned.\n",
    "    keyword_tag, # Id for the dataframe\n",
    "    keywords, # List of words, see how sentiment for this class changes over time.\n",
    "    verbose = True\n",
    "):\n",
    "    if verbose: print(\"Copying df\")\n",
    "    df = df_pass.copy()\n",
    "\n",
    "    if verbose: print(\"Starting fuzzy matching\")\n",
    "    df[f'{keyword_tag}_idx'] = df['sentences'].swifter\\\n",
    "    .apply(lambda x: fuzzy_colocation(x, keywords))\n",
    "    \n",
    "    # For each document we now have a list of sentences that express some emotion\n",
    "    # Average over them.\n",
    "    def calculate_mean_em(row):\n",
    "        emotions_size = len(row['emotions_vecs'])\n",
    "        return np.mean([row['emotions_vecs'][idx] \n",
    "                   for idx in row[f'{keyword_tag}_idx'] \n",
    "                   if idx < emotions_size], axis=0).tolist()\n",
    "    \n",
    "    if verbose: print(\"Calculating mean emotion per document per keyword\")\n",
    "    df[f'{keyword_tag}'] = df.swifter.apply(calculate_mean_em, axis = 1)\n",
    "    return df\n",
    "\n",
    "def plot_keyword_dep(\n",
    "    df,\n",
    "    keyword_tag,\n",
    "    emotion_map\n",
    "):\n",
    "    view = df[f'{keyword_tag}'].apply(pd.Series)\n",
    "    view = view.rename(columns = lambda col: emotion_map[col])\n",
    "\n",
    "    plt.figure()\n",
    "    view.plot()\n",
    "    plt.figure()\n",
    "    view_rolling = view.rolling('248d').mean()\n",
    "    view_rolling.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekman_list = ['anger', \n",
    "              'disgust', \n",
    "              'fear', \n",
    "              'joy', \n",
    "              'sadness', \n",
    "              'surprise', \n",
    "              'neutral']\n",
    "ekman_map = dict(zip(ekman_list, range(len(ekman_list))))\n",
    "\n",
    "positive_emotions = ['admiration', \n",
    "                     'amusement',\n",
    "                     'approval',\n",
    "                     'caring',\n",
    "                     'desire',\n",
    "                     'excitement',\n",
    "                     'gratitude',\n",
    "                     'joy',\n",
    "                     'love',\n",
    "                     'optimism',\n",
    "                     'pride',\n",
    "                     'relief']\n",
    "negative_emotions = ['anger',\n",
    "                     'annoyance',\n",
    "                     'disappointment',\n",
    "                     'disapproval',\n",
    "                     'disgust',\n",
    "                     'embarrassment',\n",
    "                     'fear',\n",
    "                     'grief',\n",
    "                     'nervousness',\n",
    "                     'remorse',\n",
    "                     'sadness']\n",
    "ambiguous_emotions = ['confusion',\n",
    "                      'curiosity',\n",
    "                      'realization',\n",
    "                      'surprise']\n",
    "neutral_emotions = ['neutral']\n",
    "\n",
    "emotions_list = positive_emotions + negative_emotions + ambiguous_emotions + neutral_emotions\n",
    "emotions_map = dict(zip(emotions_list, range(len(emotions_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e0383c6857418c831f95270799c494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=75610.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pad emotion into a vector \n",
    "df[f'emotions_vecs'] = df['sentences_emotions'].swifter\\\n",
    "    .apply(lambda emotions: [vectorise_emotion(emotion, ekman_map) \n",
    "                             for emotion in emotions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "woi = {\n",
    "    'ind': ['aboriginal', 'first nations', 'aborigine', 'indigenous', 'torres strait island'],\n",
    "    'econ': ['economy', 'economic'],\n",
    "    'aus': ['australia', 'australian', 'aussie', 'australians'],\n",
    "    'gov': ['government'],\n",
    "    'ref': ['immigrant', 'asylum seeker', 'boat people', 'illegal arrivals', 'boat arrivals'],\n",
    "    'env': ['fire', 'bushfire', 'climate change', 'climate action', 'extinction', 'global warming', 'greenhouse', 'emissions', 'environment', 'coral reef', 'reef', 'climate', 'degradation', 'sustainability']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying df\n",
      "Starting fuzzy matching\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac7234dc3074f0bba25d64fa22b1646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=75610.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ = df.copy()\n",
    "for key in woi:\n",
    "    df_ = generate_keyword_in_context_sentiment(df_, key, woi[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_keyword_dep(df_, 'ref', list(ekman_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_keyword_dep(df_, 'aus', list(ekman_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_keyword_dep(df_, 'econ', list(ekman_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_keyword_dep(df_, 'ind', list(ekman_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_keyword_dep(df_, 'gov', list(ekman_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_keyword_dep(df_, 'env', list(ekman_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
