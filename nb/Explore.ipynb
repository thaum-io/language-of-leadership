{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add repo\n",
    "git_dir = os.path.abspath('../')\n",
    "sys.path.append(os.path.join(git_dir, 'lib', 'GoEmotions-pytorch') )\n",
    "sys.path.append(os.path.join(git_dir, 'lib', 'utils') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from model import BertForMultiLabelClassification\n",
    "from multilabel_pipeline import MultiLabelPipeline\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add repo\n",
    "git_dir = os.path.abspath('../')\n",
    "sys.path.append(os.path.join(git_dir, 'lib', 'utils') )\n",
    "\n",
    "# Define data output path\n",
    "transcript_path = os.path.join(git_dir, 'data', 'pm-transcripts-processed/aggregated-spellfixed-typed.csv')\n",
    "df = pd.read_csv(transcript_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pm</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Abbott, Tony</td>\n",
       "      <td>24/08/2014</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>Every day the Government is working to build a...</td>\n",
       "      <td>['every day the government is working to build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gorton, John</td>\n",
       "      <td>14/03/1968</td>\n",
       "      <td>Statement in Parliament</td>\n",
       "      <td>STATEMENT BY THE PRIME MINISTER, THE RT. HON....</td>\n",
       "      <td>['the house of representatives on a of march o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Turnbull, Malcolm</td>\n",
       "      <td>17/11/2016</td>\n",
       "      <td>Transcript</td>\n",
       "      <td>PRIME MINISTER: This is a great initiative. Wh...</td>\n",
       "      <td>['what you re seeing here is real enthusiasm f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fraser, Malcolm</td>\n",
       "      <td>27/09/1978</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>FOR PRESS 27 SEPTEMBER, 1978 GRANT TO WORLD W...</td>\n",
       "      <td>['for press of september of of grant to world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Howard, John</td>\n",
       "      <td>24/03/2004</td>\n",
       "      <td>Interview</td>\n",
       "      <td>JOURNALIST: Prime Minister, is Mark Latham pla...</td>\n",
       "      <td>['journalist prime minister is mark latham pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 pm        date                     type  \\\n",
       "0           0       Abbott, Tony  24/08/2014            Media Release   \n",
       "1           1       Gorton, John  14/03/1968  Statement in Parliament   \n",
       "2           2  Turnbull, Malcolm  17/11/2016               Transcript   \n",
       "3           3    Fraser, Malcolm  27/09/1978            Media Release   \n",
       "4           4       Howard, John  24/03/2004                Interview   \n",
       "\n",
       "                                             content  \\\n",
       "0  Every day the Government is working to build a...   \n",
       "1   STATEMENT BY THE PRIME MINISTER, THE RT. HON....   \n",
       "2  PRIME MINISTER: This is a great initiative. Wh...   \n",
       "3   FOR PRESS 27 SEPTEMBER, 1978 GRANT TO WORLD W...   \n",
       "4  JOURNALIST: Prime Minister, is Mark Latham pla...   \n",
       "\n",
       "                                           sentences  \n",
       "0  ['every day the government is working to build...  \n",
       "1  ['the house of representatives on a of march o...  \n",
       "2  ['what you re seeing here is real enthusiasm f...  \n",
       "3  ['for press of september of of grant to world ...  \n",
       "4  ['journalist prime minister is mark latham pla...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = df[((df['type']=='Speech') | (df['type']=='Media Release'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 910/13674 [01:05<17:24, 12.22it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 911 in document 23 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1510/13674 [01:49<20:01, 10.12it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
      " 11%|█         | 1513/13674 [01:49<17:46, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1512 in document 20 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1526/13674 [01:50<22:46,  8.89it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
      " 11%|█         | 1528/13674 [01:51<21:13,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1526 in document 8 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1538/13674 [01:51<13:57, 14.48it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1538 in document 6 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1769/13674 [02:06<19:53,  9.97it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1769 in document 505 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1952/13674 [02:20<08:12, 23.82it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
      " 14%|█▍        | 1956/13674 [02:20<07:16, 26.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1952 in document 0 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 3257/13674 [04:06<15:52, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3250 in document 9 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 3272/13674 [04:07<10:26, 16.60it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3273 in document 26 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 3363/13674 [04:13<12:42, 13.52it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
      " 25%|██▍       | 3365/13674 [04:13<12:01, 14.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3363 in document 71 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3683/13674 [04:37<20:29,  8.12it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3685 in document 11 is too long\n",
      "Sentence 3685 in document 21 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 4159/13674 [05:11<07:55, 20.02it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
      " 30%|███       | 4162/13674 [05:11<08:53, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 4161 in document 2 is too long\n",
      "Sentence 4161 in document 3 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 4585/13674 [05:41<11:37, 13.02it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      " 34%|███▎      | 4588/13674 [05:42<11:35, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 4586 in document 37 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 4664/13674 [05:48<25:05,  5.99it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      " 34%|███▍      | 4666/13674 [05:48<20:18,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 4665 in document 20 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 6419/13674 [08:02<06:22, 18.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 6418 in document 7 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 6657/13674 [08:20<05:43, 20.41it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 6657 in document 7 is too long\n",
      "Sentence 6657 in document 30 is too long\n",
      "Sentence 6657 in document 31 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 7036/13674 [08:50<17:39,  6.27it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 7036 in document 67 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 8272/13674 [10:30<05:24, 16.63it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
      " 61%|██████    | 8275/13674 [10:31<06:57, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 8274 in document 32 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 8374/13674 [10:39<07:40, 11.51it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      " 61%|██████▏   | 8377/13674 [10:39<06:17, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 8376 in document 8 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8530/13674 [10:49<05:34, 15.37it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
      " 62%|██████▏   | 8534/13674 [10:49<04:55, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 8532 in document 18 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 9124/13674 [11:32<05:08, 14.72it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      " 67%|██████▋   | 9127/13674 [11:33<04:22, 17.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9126 in document 9 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 9268/13674 [11:43<07:39,  9.59it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
      " 68%|██████▊   | 9272/13674 [11:43<06:01, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9269 in document 23 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 9326/13674 [11:47<07:09, 10.13it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9327 in document 1 is too long\n",
      "Sentence 9327 in document 18 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 9366/13674 [11:49<03:52, 18.53it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
      " 69%|██████▊   | 9370/13674 [11:49<03:51, 18.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9367 in document 9 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9408/13674 [11:53<11:10,  6.36it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
      " 69%|██████▉   | 9410/13674 [11:53<09:25,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9408 in document 28 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 11074/13674 [13:55<05:28,  7.92it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11077 in document 2 is too long\n",
      "Sentence 11077 in document 3 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 11640/13674 [14:35<03:50,  8.83it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11640 in document 18 is too long\n",
      "Sentence 11640 in document 19 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 11738/13674 [14:44<02:58, 10.87it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      " 86%|████████▌ | 11741/13674 [14:44<02:40, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11738 in document 13 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 11829/13674 [14:50<02:10, 14.19it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      " 87%|████████▋ | 11837/13674 [14:50<01:32, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11830 in document 5 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 12105/13674 [15:12<04:33,  5.73it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12105 in document 0 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 12128/13674 [15:14<03:30,  7.35it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
      " 89%|████████▊ | 12134/13674 [15:15<02:38,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12130 in document 4 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 12236/13674 [15:22<01:42, 13.99it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12237 in document 11 is too long\n",
      "Sentence 12237 in document 12 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 12807/13674 [16:04<00:52, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12806 in document 16 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 13454/13674 [16:56<00:10, 20.86it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 13454 in document 28 is too long\n",
      "Sentence 13454 in document 30 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 13666/13674 [17:12<00:00, 20.04it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 13667 in document 16 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13674/13674 [17:12<00:00, 13.24it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model = BertForMultiLabelClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model = model.to('cuda:0')\n",
    "\n",
    "goemotions = MultiLabelPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    threshold=0.3,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "\n",
    "processed_sentence_lists = []\n",
    "for ind, sentence_list_repr in enumerate(tqdm(df_speeches['sentences'])):\n",
    "    processed_sentences = []\n",
    "    \n",
    "    sentence_list_raw = eval(sentence_list_repr)\n",
    "    sentence_list = []\n",
    "    \n",
    "    for sentence_ind, sentence in enumerate(sentence_list_raw):\n",
    "        tokens = tokenizer(sentence)\n",
    "        if len(tokens['input_ids'])>500:\n",
    "            print('Sentence %d in document %d is too long'%(sentence_ind, ind))\n",
    "        else:\n",
    "            sentence_list.append(sentence)\n",
    "    \n",
    "    for batch in batch_gen(sentence_list, n=32):\n",
    "        processed_sentences.extend(goemotions(batch))\n",
    "        #processed_sentences.append(goemotions(sentence)[0])\n",
    "            #ts['emotions'].append(goemotions(sentence)[0])\n",
    "    processed_sentence_lists.append(processed_sentences)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_processed = df_speeches.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_processed['sentences_emotions'] = processed_sentence_lists\n",
    "#processed_sentence_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pm</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Abbott, Tony</td>\n",
       "      <td>24/08/2014</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>Every day the Government is working to build a...</td>\n",
       "      <td>['every day the government is working to build...</td>\n",
       "      <td>[{'labels': ['approval', 'optimism', 'realizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fraser, Malcolm</td>\n",
       "      <td>27/09/1978</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>FOR PRESS 27 SEPTEMBER, 1978 GRANT TO WORLD W...</td>\n",
       "      <td>['for press of september of of grant to world ...</td>\n",
       "      <td>[{'labels': ['neutral'], 'scores': [0.9980432]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Fraser, Malcolm</td>\n",
       "      <td>21/07/1976</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>FOR PRESS 21 July 1976 SENATOR COTTON TO LEAD...</td>\n",
       "      <td>['for press of july of of senator cotton to le...</td>\n",
       "      <td>[{'labels': ['neutral'], 'scores': [0.9990237]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Gillard, Julia</td>\n",
       "      <td>25/08/2011</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>Patients and families in regional communities...</td>\n",
       "      <td>['patients and families in regional communitie...</td>\n",
       "      <td>[{'labels': ['approval', 'neutral'], 'scores':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Hawke, Robert</td>\n",
       "      <td>06/06/1986</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>PRIMEST AINIE FOR MEDIA 6 JUNE 1986 I am plea...</td>\n",
       "      <td>['priest annie for media a june of of i am ple...</td>\n",
       "      <td>[{'labels': ['neutral'], 'scores': [0.9751662]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0               pm        date           type  \\\n",
       "0            0     Abbott, Tony  24/08/2014  Media Release   \n",
       "3            3  Fraser, Malcolm  27/09/1978  Media Release   \n",
       "8            8  Fraser, Malcolm  21/07/1976  Media Release   \n",
       "9            9   Gillard, Julia  25/08/2011  Media Release   \n",
       "12          12    Hawke, Robert  06/06/1986  Media Release   \n",
       "\n",
       "                                              content  \\\n",
       "0   Every day the Government is working to build a...   \n",
       "3    FOR PRESS 27 SEPTEMBER, 1978 GRANT TO WORLD W...   \n",
       "8    FOR PRESS 21 July 1976 SENATOR COTTON TO LEAD...   \n",
       "9    Patients and families in regional communities...   \n",
       "12   PRIMEST AINIE FOR MEDIA 6 JUNE 1986 I am plea...   \n",
       "\n",
       "                                            sentences  \\\n",
       "0   ['every day the government is working to build...   \n",
       "3   ['for press of september of of grant to world ...   \n",
       "8   ['for press of july of of senator cotton to le...   \n",
       "9   ['patients and families in regional communitie...   \n",
       "12  ['priest annie for media a june of of i am ple...   \n",
       "\n",
       "                                   sentences_emotions  \n",
       "0   [{'labels': ['approval', 'optimism', 'realizat...  \n",
       "3   [{'labels': ['neutral'], 'scores': [0.9980432]...  \n",
       "8   [{'labels': ['neutral'], 'scores': [0.9990237]...  \n",
       "9   [{'labels': ['approval', 'neutral'], 'scores':...  \n",
       "12  [{'labels': ['neutral'], 'scores': [0.9751662]...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speeches_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string repr of sentences dicts back into dicts\n",
    "df_speeches_processed['sentences'] = df_speeches_processed['sentences'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_processed.to_pickle( os.path.join(git_dir, 'data', 'pm-transcripts-processed', 'aggregated-spellfixed-typed-emotions.pkl') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"thank you or bartholomew reverend summer my parliamentary colleagues irish draper chris pine and joe scale or mayor ladies and gentlemen. its a beautiful adelaide morning and its a great pleasure to be with you and to share a few moments in opening these new facilities which are the product of wonderful work of lutheran aged care here in south australia. let me say how much i admire and the government admires the contribution that over the years church based aged care facilities have made to the caring of the aged in australia. they have in so many ways been the example that has been followed by others and i hope for years into the future whenever we think in australia of aged care facilities we think automatically of the contribution that has been made by so many of the churches and other religiously connected organisations to the care of the aged in australia. in common with all other societies that are like australia we are an ageing country. the number of people over the age of of will grow as the years go by and the proportion of people of working age will diminish. this raises a number of challenges for governments well into the future. one part of that challenge will of course be in the area of aged care facilities. it is the philosophy of our government that we should assist people to remain in their own homes as long as is possible and indeed the great bulk of people are able to realise that goal. we provide through the community care packages increased facilities to assist people to go on living for longer periods of time in their own homes. but we also recognise that there will come a point for many people where that is no longer either possible or as a matter of choice desirable. and therefore the other element is to provide the appropriate levels of support and the appropriate incentives for the maintenance of a network of aged care facilities of retirement villages of hostels and of nursing homes. and there is no better environment in which to provide those facilities than an environment which is underpinned by the care and the compassion and the commitment through their common faith of religious based organisations. and lutheran homes are a wonderful example of that and i want to thank you again for the contribution that you have made over the years. quite rightly your chairman pointed to the governments examination of the hogan review into the pricing and other aspects of aged care homes. it is an issue which is in front of the government literally at the moment and i can assure you that the recommendations of that committee and the importance that is placed by that committee on the maintenance of proper and reasonable levels of funding from the commonwealth government will be examined very carefully. we regard the care of the aged the proper looking after of people who have given so much to this country as i look out on this audience i think of a truly heroic generation many of whom went through a depression and a world war world war ii were part of the great post world war rebuilding of this country when we welcomed millions of people from other parts of the world and together all of us created the stable harmonious modern australia we owe your generation a great debt and we will not walk away from that responsibility. we have of course as a government responsibilities to many sectors of society. i did an interview this morning and in the space of about of minutes on radio i was asked when are you going to cut tax on this that and the other and i was of course asked when are you going to spend some more money and of course you all keep the economy ticking over well and the budget in balance. you just have to juggle a few balls in the air and its extremely easy. we can never satisfy everybody completely all of the time. we have to make judgements we have to make choices but i can assure you that we will conscientiously address the needs of the aged care sector. can i just finally say if i may be permitted to do so at such a gathering as this to speak of the personal qualities of your two federal representatives who are here today. in fact you have had some very famous people who have worked here over the years. and she brings to her parliamentary duties because of her background in caring for people a great understanding and also her commitment to our services. and chris pine in whose electorate this home is located i also commend to you to all of you his great energy and his great commitment and his concern to look after the interests of everybody in the community. i'm not leaving you out joe but you know they re just my federal mates and i wanted to say something about them. he a a hard working bloke too and i wouldn't want anybody to forget that. but ladies and gentlemen its great to share such a lovely morning with you. i started off this morning going for a walk along the torrens river and as you know i do a lot of walking everywhere in the world and there in to a nicer part of australia in which to go for a walk than that beautiful torrens river. i can see the adelaide oval out of the corner of my eye and that sort of keeps me very very happy. and i have great pleasure in declaring these new facilities well and truly open and long may you all live peacefully and happily in a supportive christian environment in these wonderful facilities\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat using Ekman Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from model import BertForMultiLabelClassification\n",
    "from multilabel_pipeline import MultiLabelPipeline\n",
    "from pprint import pprint\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-ekman\")\n",
    "model = BertForMultiLabelClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-ekman\")\n",
    "model = model.to('cuda:0')\n",
    "\n",
    "goemotions = MultiLabelPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    threshold=0.3,\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = df[((df['type']=='Speech') | (df['type']=='Media Release'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 910/13674 [01:03<17:07, 12.42it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 911 in document 23 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1510/13674 [01:47<19:36, 10.34it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
      " 11%|█         | 1513/13674 [01:47<17:24, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1512 in document 20 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1526/13674 [01:48<22:25,  9.03it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
      " 11%|█         | 1528/13674 [01:48<20:54,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1526 in document 8 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1537/13674 [01:49<15:04, 13.41it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1538 in document 6 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1769/13674 [02:04<19:31, 10.16it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1769 in document 505 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1952/13674 [02:17<08:07, 24.05it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
      " 14%|█▍        | 1956/13674 [02:17<07:10, 27.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1952 in document 0 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 3257/13674 [04:03<15:41, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3250 in document 9 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 3272/13674 [04:03<10:23, 16.70it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3273 in document 26 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 3363/13674 [04:09<12:32, 13.71it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
      " 25%|██▍       | 3365/13674 [04:09<11:49, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3363 in document 71 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3683/13674 [04:33<20:15,  8.22it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3685 in document 11 is too long\n",
      "Sentence 3685 in document 21 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 4159/13674 [05:06<07:47, 20.36it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
      " 30%|███       | 4162/13674 [05:07<08:48, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 4161 in document 2 is too long\n",
      "Sentence 4161 in document 3 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 4585/13674 [05:37<11:27, 13.22it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      " 34%|███▎      | 4588/13674 [05:37<11:26, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 4586 in document 37 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 4664/13674 [05:44<24:41,  6.08it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      " 34%|███▍      | 4669/13674 [05:44<15:44,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 4665 in document 20 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 6419/13674 [07:56<06:18, 19.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 6418 in document 7 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 6657/13674 [08:14<05:39, 20.67it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 6657 in document 7 is too long\n",
      "Sentence 6657 in document 30 is too long\n",
      "Sentence 6657 in document 31 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 7035/13674 [08:44<16:56,  6.53it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 7036 in document 67 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 8272/13674 [10:23<05:21, 16.79it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
      " 61%|██████    | 8275/13674 [10:23<06:55, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 8274 in document 32 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 8374/13674 [10:32<07:34, 11.66it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      " 61%|██████▏   | 8377/13674 [10:32<06:14, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 8376 in document 8 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8530/13674 [10:41<05:33, 15.42it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
      " 62%|██████▏   | 8534/13674 [10:41<04:52, 17.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 8532 in document 18 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 9124/13674 [11:25<05:06, 14.84it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      " 67%|██████▋   | 9127/13674 [11:25<04:20, 17.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9126 in document 9 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 9268/13674 [11:35<07:33,  9.71it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
      " 68%|██████▊   | 9272/13674 [11:35<05:56, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9269 in document 23 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 9326/13674 [11:39<07:03, 10.26it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9327 in document 1 is too long\n",
      "Sentence 9327 in document 18 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 9366/13674 [11:41<03:49, 18.74it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
      " 69%|██████▊   | 9370/13674 [11:41<03:47, 18.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9367 in document 9 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9408/13674 [11:45<10:58,  6.48it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
      " 69%|██████▉   | 9410/13674 [11:45<09:12,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9408 in document 28 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 11074/13674 [13:46<05:23,  8.05it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11077 in document 2 is too long\n",
      "Sentence 11077 in document 3 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 11640/13674 [14:25<03:49,  8.88it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11640 in document 18 is too long\n",
      "Sentence 11640 in document 19 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 11738/13674 [14:33<02:55, 11.01it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      " 86%|████████▌ | 11741/13674 [14:34<02:39, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11738 in document 13 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 11829/13674 [14:40<02:08, 14.34it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      " 87%|████████▋ | 11837/13674 [14:40<01:31, 20.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11830 in document 5 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 12105/13674 [15:02<04:30,  5.79it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 512). Running this sequence through the model will result in indexing errors\n",
      " 89%|████████▊ | 12107/13674 [15:02<04:01,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12105 in document 0 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 12128/13674 [15:04<03:28,  7.40it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
      " 89%|████████▊ | 12134/13674 [15:04<02:37,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12130 in document 4 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 12236/13674 [15:11<01:41, 14.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12237 in document 11 is too long\n",
      "Sentence 12237 in document 12 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 12807/13674 [15:53<00:52, 16.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12806 in document 16 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 13454/13674 [16:45<00:10, 20.95it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 13454 in document 28 is too long\n",
      "Sentence 13454 in document 30 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 13666/13674 [17:00<00:00, 20.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 13667 in document 16 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13674/13674 [17:01<00:00, 13.39it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_sentence_lists = []\n",
    "for ind, sentence_list_repr in enumerate(tqdm(df_speeches['sentences'])):\n",
    "    processed_sentences = []\n",
    "    \n",
    "    sentence_list_raw = eval(sentence_list_repr)\n",
    "    sentence_list = []\n",
    "    \n",
    "    for sentence_ind, sentence in enumerate(sentence_list_raw):\n",
    "        tokens = tokenizer(sentence)\n",
    "        if len(tokens['input_ids'])>500:\n",
    "            print('Sentence %d in document %d is too long'%(sentence_ind, ind ))\n",
    "        else:\n",
    "            sentence_list.append(sentence)\n",
    "    \n",
    "    for batch in batch_gen(sentence_list, n=32):\n",
    "        processed_sentences.extend(goemotions(batch))\n",
    "        #processed_sentences.append(goemotions(sentence)[0])\n",
    "            #ts['emotions'].append(goemotions(sentence)[0])\n",
    "    processed_sentence_lists.append(processed_sentences)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_processed = df_speeches.copy()\n",
    "df_speeches_processed['sentences_emotions'] = processed_sentence_lists\n",
    "\n",
    "# Convert string repr of sentences dicts back into dicts\n",
    "df_speeches_processed['sentences'] = df_speeches_processed['sentences'].apply(lambda x: eval(x))\n",
    "\n",
    "# Save\n",
    "df_speeches_processed.to_pickle( os.path.join(git_dir, 'data', 'pm-transcripts-processed', 'aggregated-spellfixed-typed-emotions-ekman.pkl') )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
