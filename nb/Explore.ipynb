{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add repo\n",
    "git_dir = os.path.abspath('../')\n",
    "sys.path.append(os.path.join(git_dir, 'lib', 'GoEmotions-pytorch') )\n",
    "sys.path.append(os.path.join(git_dir, 'lib', 'utils') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from model import BertForMultiLabelClassification\n",
    "from multilabel_pipeline import MultiLabelPipeline\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add repo\n",
    "git_dir = os.path.abspath('../')\n",
    "sys.path.append(os.path.join(git_dir, 'lib', 'utils') )\n",
    "\n",
    "# Define data output path\n",
    "transcript_path = os.path.join(git_dir, 'data', 'pm-transcripts-processed/aggregated-spellfixed-typed.csv')\n",
    "df = pd.read_csv(transcript_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['content'] = df['content'].str.replace(u'\\xa0', u' ')\n",
    "# df['content'] = df['content'].str.replace(' \\]\\]\\>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pm</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Abbott, Tony</td>\n",
       "      <td>24/08/2014</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>Every day the Government is working to build a...</td>\n",
       "      <td>['every day the government is working to build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gorton, John</td>\n",
       "      <td>14/03/1968</td>\n",
       "      <td>Statement in Parliament</td>\n",
       "      <td>STATEMENT BY THE PRIME MINISTER, THE RT. HON....</td>\n",
       "      <td>['the house of representatives on a of march o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Turnbull, Malcolm</td>\n",
       "      <td>17/11/2016</td>\n",
       "      <td>Transcript</td>\n",
       "      <td>PRIME MINISTER: This is a great initiative. Wh...</td>\n",
       "      <td>['what you re seeing here is real enthusiasm f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fraser, Malcolm</td>\n",
       "      <td>27/09/1978</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>FOR PRESS 27 SEPTEMBER, 1978 GRANT TO WORLD W...</td>\n",
       "      <td>['for press of september of of grant to world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Howard, John</td>\n",
       "      <td>24/03/2004</td>\n",
       "      <td>Interview</td>\n",
       "      <td>JOURNALIST: Prime Minister, is Mark Latham pla...</td>\n",
       "      <td>['journalist prime minister is mark latham pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 pm        date                     type  \\\n",
       "0           0       Abbott, Tony  24/08/2014            Media Release   \n",
       "1           1       Gorton, John  14/03/1968  Statement in Parliament   \n",
       "2           2  Turnbull, Malcolm  17/11/2016               Transcript   \n",
       "3           3    Fraser, Malcolm  27/09/1978            Media Release   \n",
       "4           4       Howard, John  24/03/2004                Interview   \n",
       "\n",
       "                                             content  \\\n",
       "0  Every day the Government is working to build a...   \n",
       "1   STATEMENT BY THE PRIME MINISTER, THE RT. HON....   \n",
       "2  PRIME MINISTER: This is a great initiative. Wh...   \n",
       "3   FOR PRESS 27 SEPTEMBER, 1978 GRANT TO WORLD W...   \n",
       "4  JOURNALIST: Prime Minister, is Mark Latham pla...   \n",
       "\n",
       "                                           sentences  \n",
       "0  ['every day the government is working to build...  \n",
       "1  ['the house of representatives on a of march o...  \n",
       "2  ['what you re seeing here is real enthusiasm f...  \n",
       "3  ['for press of september of of grant to world ...  \n",
       "4  ['journalist prime minister is mark latham pla...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = df[((df['type']=='Speech') | (df['type']=='Media Release'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 910/13674 [01:05<17:24, 12.22it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 911 in document 23 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1510/13674 [01:49<20:01, 10.12it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
      " 11%|█         | 1513/13674 [01:49<17:46, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1512 in document 20 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1526/13674 [01:50<22:46,  8.89it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
      " 11%|█         | 1528/13674 [01:51<21:13,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1526 in document 8 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1538/13674 [01:51<13:57, 14.48it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1538 in document 6 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1769/13674 [02:06<19:53,  9.97it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1769 in document 505 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1952/13674 [02:20<08:12, 23.82it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
      " 14%|█▍        | 1956/13674 [02:20<07:16, 26.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1952 in document 0 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 3257/13674 [04:06<15:52, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3250 in document 9 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 3272/13674 [04:07<10:26, 16.60it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3273 in document 26 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 3363/13674 [04:13<12:42, 13.52it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
      " 25%|██▍       | 3365/13674 [04:13<12:01, 14.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3363 in document 71 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3683/13674 [04:37<20:29,  8.12it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 3685 in document 11 is too long\n",
      "Sentence 3685 in document 21 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 4159/13674 [05:11<07:55, 20.02it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
      " 30%|███       | 4162/13674 [05:11<08:53, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 4161 in document 2 is too long\n",
      "Sentence 4161 in document 3 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 4585/13674 [05:41<11:37, 13.02it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      " 34%|███▎      | 4588/13674 [05:42<11:35, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 4586 in document 37 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 4664/13674 [05:48<25:05,  5.99it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      " 34%|███▍      | 4666/13674 [05:48<20:18,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 4665 in document 20 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 6419/13674 [08:02<06:22, 18.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 6418 in document 7 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 6657/13674 [08:20<05:43, 20.41it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 6657 in document 7 is too long\n",
      "Sentence 6657 in document 30 is too long\n",
      "Sentence 6657 in document 31 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 7036/13674 [08:50<17:39,  6.27it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 7036 in document 67 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 8272/13674 [10:30<05:24, 16.63it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
      " 61%|██████    | 8275/13674 [10:31<06:57, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 8274 in document 32 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 8374/13674 [10:39<07:40, 11.51it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      " 61%|██████▏   | 8377/13674 [10:39<06:17, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 8376 in document 8 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8530/13674 [10:49<05:34, 15.37it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
      " 62%|██████▏   | 8534/13674 [10:49<04:55, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 8532 in document 18 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 9124/13674 [11:32<05:08, 14.72it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      " 67%|██████▋   | 9127/13674 [11:33<04:22, 17.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9126 in document 9 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 9268/13674 [11:43<07:39,  9.59it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
      " 68%|██████▊   | 9272/13674 [11:43<06:01, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9269 in document 23 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 9326/13674 [11:47<07:09, 10.13it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9327 in document 1 is too long\n",
      "Sentence 9327 in document 18 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 9366/13674 [11:49<03:52, 18.53it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
      " 69%|██████▊   | 9370/13674 [11:49<03:51, 18.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9367 in document 9 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 9408/13674 [11:53<11:10,  6.36it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
      " 69%|██████▉   | 9410/13674 [11:53<09:25,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 9408 in document 28 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 11074/13674 [13:55<05:28,  7.92it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11077 in document 2 is too long\n",
      "Sentence 11077 in document 3 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 11640/13674 [14:35<03:50,  8.83it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11640 in document 18 is too long\n",
      "Sentence 11640 in document 19 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 11738/13674 [14:44<02:58, 10.87it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      " 86%|████████▌ | 11741/13674 [14:44<02:40, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11738 in document 13 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 11829/13674 [14:50<02:10, 14.19it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      " 87%|████████▋ | 11837/13674 [14:50<01:32, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 11830 in document 5 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 12105/13674 [15:12<04:33,  5.73it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12105 in document 0 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 12128/13674 [15:14<03:30,  7.35it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
      " 89%|████████▊ | 12134/13674 [15:15<02:38,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12130 in document 4 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 12236/13674 [15:22<01:42, 13.99it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12237 in document 11 is too long\n",
      "Sentence 12237 in document 12 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 12807/13674 [16:04<00:52, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 12806 in document 16 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 13454/13674 [16:56<00:10, 20.86it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 13454 in document 28 is too long\n",
      "Sentence 13454 in document 30 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 13666/13674 [17:12<00:00, 20.04it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 13667 in document 16 is too long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13674/13674 [17:12<00:00, 13.24it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model = BertForMultiLabelClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model = model.to('cuda:0')\n",
    "\n",
    "goemotions = MultiLabelPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    threshold=0.3,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "\n",
    "processed_sentence_lists = []\n",
    "for ind, sentence_list_repr in enumerate(tqdm(df_speeches['sentences'])):\n",
    "    processed_sentences = []\n",
    "    \n",
    "    sentence_list_raw = eval(sentence_list_repr)\n",
    "    sentence_list = []\n",
    "    \n",
    "    for sentence_ind, sentence in enumerate(sentence_list_raw):\n",
    "        tokens = tokenizer(sentence)\n",
    "        if len(tokens['input_ids'])>500:\n",
    "            print('Sentence %d in document %d is too long'%(ind, sentence_ind))\n",
    "        else:\n",
    "            sentence_list.append(sentence)\n",
    "    \n",
    "    for batch in batch_gen(sentence_list, n=32):\n",
    "        processed_sentences.extend(goemotions(batch))\n",
    "        #processed_sentences.append(goemotions(sentence)[0])\n",
    "            #ts['emotions'].append(goemotions(sentence)[0])\n",
    "    processed_sentence_lists.append(processed_sentences)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'labels': ['neutral'], 'scores': [0.99498135]},\n",
       " {'labels': ['neutral'], 'scores': [0.9990583]},\n",
       " {'labels': ['caring', 'desire'], 'scores': [0.9703579, 0.360673]},\n",
       " {'labels': ['admiration', 'neutral'], 'scores': [0.40888488, 0.991501]},\n",
       " {'labels': ['joy'], 'scores': [0.9819531]},\n",
       " {'labels': ['desire', 'optimism'], 'scores': [0.4751356, 0.95900327]}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentence_lists[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13674"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['every day the government is working to build a stronger economy so that we can help australians families and small businesses',\n",
       " 'a stronger economy means more investment more exports and more jobs',\n",
       " 'now with the return of parliament on tuesday the government is continuing to put in place the policies that are part of our economic action strategy',\n",
       " 'these policies are already making it easier for businesses to compete and to employ more people',\n",
       " 'in the last week of parliament we scrapped the carbon tax and the benefits are already filtering through were working with the senate to scrap the mining tax a tax that is raised little yet costs much',\n",
       " 'we will cut company tax making it easier for many small businesses and our record of billion infrastructure programme is underway',\n",
       " 'this programme means that major works are happening in our cities and regional areas',\n",
       " 'and because jobs depend on major investments were clearing the backlog of environmental approvals with approvals already provided for of a billion in new projects since the election',\n",
       " 'the government is also opening the door to more trade and more jobs with free trade agreements with partners like japan and korea and we are working on an agreement with our largest trading partner of all china',\n",
       " \"we are continuing to repair the budget because i don't want to see our children saddled with a debt that robs them of their futures\",\n",
       " 'we owe it to them to live within our means to invest in our future and to get spending under control',\n",
       " 'australia has now had of years of economic growth it is a remarkable achievement that owes so much to the economically responsible decisions of the hawke and howard governments',\n",
       " 'this government is continuing that tradition of supporting sensible and reforming policies so that we can build a stronger and more prosperous economy for the benefit of every australian']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(df_speeches['sentences'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_processed = df_speeches.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_processed['sentences_emotions'] = processed_sentence_lists\n",
    "#processed_sentence_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pm</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Abbott, Tony</td>\n",
       "      <td>24/08/2014</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>Every day the Government is working to build a...</td>\n",
       "      <td>['every day the government is working to build...</td>\n",
       "      <td>[{'labels': ['approval', 'optimism', 'realizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fraser, Malcolm</td>\n",
       "      <td>27/09/1978</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>FOR PRESS 27 SEPTEMBER, 1978 GRANT TO WORLD W...</td>\n",
       "      <td>['for press of september of of grant to world ...</td>\n",
       "      <td>[{'labels': ['neutral'], 'scores': [0.9980432]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Fraser, Malcolm</td>\n",
       "      <td>21/07/1976</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>FOR PRESS 21 July 1976 SENATOR COTTON TO LEAD...</td>\n",
       "      <td>['for press of july of of senator cotton to le...</td>\n",
       "      <td>[{'labels': ['neutral'], 'scores': [0.9990237]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Gillard, Julia</td>\n",
       "      <td>25/08/2011</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>Patients and families in regional communities...</td>\n",
       "      <td>['patients and families in regional communitie...</td>\n",
       "      <td>[{'labels': ['approval', 'neutral'], 'scores':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Hawke, Robert</td>\n",
       "      <td>06/06/1986</td>\n",
       "      <td>Media Release</td>\n",
       "      <td>PRIMEST AINIE FOR MEDIA 6 JUNE 1986 I am plea...</td>\n",
       "      <td>['priest annie for media a june of of i am ple...</td>\n",
       "      <td>[{'labels': ['neutral'], 'scores': [0.9751662]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0               pm        date           type  \\\n",
       "0            0     Abbott, Tony  24/08/2014  Media Release   \n",
       "3            3  Fraser, Malcolm  27/09/1978  Media Release   \n",
       "8            8  Fraser, Malcolm  21/07/1976  Media Release   \n",
       "9            9   Gillard, Julia  25/08/2011  Media Release   \n",
       "12          12    Hawke, Robert  06/06/1986  Media Release   \n",
       "\n",
       "                                              content  \\\n",
       "0   Every day the Government is working to build a...   \n",
       "3    FOR PRESS 27 SEPTEMBER, 1978 GRANT TO WORLD W...   \n",
       "8    FOR PRESS 21 July 1976 SENATOR COTTON TO LEAD...   \n",
       "9    Patients and families in regional communities...   \n",
       "12   PRIMEST AINIE FOR MEDIA 6 JUNE 1986 I am plea...   \n",
       "\n",
       "                                            sentences  \\\n",
       "0   ['every day the government is working to build...   \n",
       "3   ['for press of september of of grant to world ...   \n",
       "8   ['for press of july of of senator cotton to le...   \n",
       "9   ['patients and families in regional communitie...   \n",
       "12  ['priest annie for media a june of of i am ple...   \n",
       "\n",
       "                                   sentences_emotions  \n",
       "0   [{'labels': ['approval', 'optimism', 'realizat...  \n",
       "3   [{'labels': ['neutral'], 'scores': [0.9980432]...  \n",
       "8   [{'labels': ['neutral'], 'scores': [0.9990237]...  \n",
       "9   [{'labels': ['approval', 'neutral'], 'scores':...  \n",
       "12  [{'labels': ['neutral'], 'scores': [0.9751662]...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speeches_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string repr of sentences dicts back into dicts\n",
    "df_speeches_processed['sentences'] = df_speeches_processed['sentences'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches_processed.to_pickle( os.path.join(git_dir, 'data', 'pm-transcripts-processed/aggregated-spellfixed-typed-emotions.pkl') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spacy]",
   "language": "python",
   "name": "conda-env-spacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
