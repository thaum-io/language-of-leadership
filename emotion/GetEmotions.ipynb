{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add repo\n",
    "git_dir = os.path.abspath('../')\n",
    "sys.path.append(os.path.join(git_dir, 'lib', 'GoEmotions-pytorch') )\n",
    "sys.path.append(os.path.join(git_dir, 'lib', 'utils') )\n",
    "\n",
    "# Define data path\n",
    "data_path = os.path.join(git_dir, 'data', 'pm-transcripts')\n",
    "\n",
    "# Define data output path\n",
    "data_output_path = os.path.join(git_dir, 'data', 'pm-transcripts-processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from model import BertForMultiLabelClassification\n",
    "from multilabel_pipeline import MultiLabelPipeline\n",
    "from pprint import pprint\n",
    "from ipywidgets import IntProgress\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model = BertForMultiLabelClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model = model.to('cuda:0')\n",
    "\n",
    "goemotions = MultiLabelPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    threshold=0.3,\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml_cleaner import get_transcript_fname_by_id, parse_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe from index\n",
    "ts_path = os.path.join(data_path, 'transcripts') # path folder of where pm-transcripts are stored\n",
    "index_file_path = os.path.join(data_path, 'index.csv')\n",
    "index_df = pd.read_csv(index_file_path)\n",
    "\n",
    "# Make output dir\n",
    "if not os.path.exists(data_output_path):\n",
    "    os.makedirs(data_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose PM\n",
    "pm_name = 'Howard, John'\n",
    "\n",
    "# Get all IDs\n",
    "ts_ids = list(index_df[index_df['pm']==pm_name]['id'].astype(int))\n",
    "\n",
    "# Iterate\n",
    "for i, ts_id in enumerate(tqdm(ts_ids)):\n",
    "    ts = parse_transcript(get_transcript_fname_by_id(ts_path, ts_id))\n",
    "    if ts is not None:\n",
    "        ts['emotions'] = [goemotions(x)[0] for x in ts['sentences']]\n",
    "        f_out = os.path.join(data_output_path, str(ts_id)+'.pkl')\n",
    "        with open(f_out, 'wb') as f:\n",
    "            pickle.dump(ts, f)Z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spacy]",
   "language": "python",
   "name": "conda-env-spacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
